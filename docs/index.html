<h1><a href="https://nyu-mll.github.io/nlu-debiasing-data">FAQ</a></h1>

<h2>Thanks for doing our HITs! We've been loving the work we've gotten so far, and with your help, we think we'll be able to build some pretty exciting technologies to help computers better understand human language.</h2>

<h3>Will you reject any of my work?</h3>
No. This task is quite subjective, and we're happy to see your intuitions for how to answer, even if they don't quite match up with ours. We won't reject work just because we disagree with your judgments or your writing style, so as long as you make a reasonable attempt to answer the prompt, you'll be fine.

<h3>Can I select multiple types of bias for a single HIT?</h3>
Yes! Please select all that are appropriate.

<h3>Not a question, but I feel bad about writing with bias!</h3>
We understand. Please don’t feel bad about writing with bias! We know these aren’t your beliefs, and we will anonymize any data that we publish.

<h3>Do you have any preferences for how we construct sentences?</h3>
You are free to construct sentences in any way you see fit. However, please avoid systematic and repetitive answers. Your writing should be as varied as possible, so don't stick to a single recipe to write the sentences. We can't use highly repetitive data.

<h3>Can I write the same sentence in more than one field, or in more than one HIT?</h3>
No. If you accidentally reuse a sentence a couple of times in the course of doing many HITs, that's fine, but try to make every sentence original.

<h3>Is there any limit to how many of these HITs I can do?</h3>
Nope! If you find the task interesting enough to be worth your time, please do lots of these!

<h3>Would you prefer that we use words in the original sentence or synonyms for those words in our own sentences?</h3>
Synonyms and repeated words are both ok. A mixture of both would be ideal, but we will accept either.

<h3>When do you approve HITs?</h3>
We are grad students buried in work, so we can't promise to look at the data directly any more often than once a day.

<h3>Who are you?</h3>
We are the Bowman Group, a subgroup of the ML2 group at New York University Center for Data Science. We are also affiliated with the NYU Departments of Computer Science and Linguistics.

<h3>Can you give more explanation about each type of social bias?</h3>
Here are some explanation (adapted from <a href="https://www.eeoc.gov/laws/">here</a>)

<ul>
<li><b>Race or color:</b>  Stereotyping or discriminating against someone because of their race or personal characteristics associated with race, such as hair texture, skin color, or certain facial features.</li>
<li><b>Gender, gender identity, or gender expression:</b> Stereotyping or discriminating against someone because of their gender, or gender identity (transgender, non-conforming identity, or perceived gender identity).</li>
<li><b>Sexual orientation:</b> Stereotyping or discriminating against someone because of their sexual orientation (gay, lesbian, straight, bisexual, asexual).</li>
<li><b>Religion:</b> Stereotyping or discriminating against someone because of their religious, ethical, or moral beliefs.</li>
<li><b>Age:</b> Stereotyping or discriminating against someone because of their age (old or young)</li>
<li><b>Disability:</b> Stereotyping or discriminating against someone because of their history of disability or because they are believed to have some physical or mental impairment.</li>
</ul>
