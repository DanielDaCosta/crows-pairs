{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read data into dataframe with one row per 'template'\n",
    "\"\"\"\n",
    "\n",
    "df_data = pd.DataFrame(columns=['sentid', 'pro_stereo_sentence', 'anti_stereo_sentence'])\n",
    "for filename in ['type1.txt.dev', 'type2.txt.dev', 'type1.txt.test', 'type2.txt.test']:\n",
    "    pro_file = 'winobias/pro_stereotyped_'+filename+'.txt'\n",
    "    anti_file = 'winobias/anti_stereotyped_'+filename+'.txt'\n",
    "    pro = [x.strip().split() for x in open(pro_file, 'r').readlines()]\n",
    "    anti = [x.strip().split() for x in open(anti_file, 'r').readlines()]\n",
    "    for i in range(len(pro)):\n",
    "        sentid = filename+'_'+pro[i][0]\n",
    "        pro_sent = ' '.join(pro[i][1:]).replace('[','').replace(']','')\n",
    "        anti_sent = ' '.join(anti[i][1:]).replace('[','').replace(']','')\n",
    "        df_data = df_data.append({'sentid':sentid,\n",
    "                                  'pro_stereo_sentence': pro_sent,\n",
    "                                  'anti_stereo_sentence': anti_sent\n",
    "                                 }, ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentid</th>\n",
       "      <th>pro_stereo_sentence</th>\n",
       "      <th>anti_stereo_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>type1.txt.dev_1</td>\n",
       "      <td>The developer argued with the designer because...</td>\n",
       "      <td>The developer argued with the designer because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>type1.txt.dev_2</td>\n",
       "      <td>The developer argued with the designer because...</td>\n",
       "      <td>The developer argued with the designer because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>type1.txt.dev_3</td>\n",
       "      <td>The mechanic gave the clerk a present because ...</td>\n",
       "      <td>The mechanic gave the clerk a present because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>type1.txt.dev_4</td>\n",
       "      <td>The mechanic gave the clerk a present because ...</td>\n",
       "      <td>The mechanic gave the clerk a present because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>type1.txt.dev_5</td>\n",
       "      <td>The mover said thank you to the housekeeper be...</td>\n",
       "      <td>The mover said thank you to the housekeeper be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentid                                pro_stereo_sentence  \\\n",
       "0  type1.txt.dev_1  The developer argued with the designer because...   \n",
       "1  type1.txt.dev_2  The developer argued with the designer because...   \n",
       "2  type1.txt.dev_3  The mechanic gave the clerk a present because ...   \n",
       "3  type1.txt.dev_4  The mechanic gave the clerk a present because ...   \n",
       "4  type1.txt.dev_5  The mover said thank you to the housekeeper be...   \n",
       "\n",
       "                                anti_stereo_sentence  \n",
       "0  The developer argued with the designer because...  \n",
       "1  The developer argued with the designer because...  \n",
       "2  The mechanic gave the clerk a present because ...  \n",
       "3  The mechanic gave the clerk a present because ...  \n",
       "4  The mover said thank you to the housekeeper be...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reformat data to extract template mask for each template (longest prefix and longest suffix)\n",
    "Other columns are only the word tokens that are different for pro and anti stereo\n",
    "\"\"\"\n",
    "\n",
    "df_templates = pd.DataFrame(columns=['sentid', 'template', 'pro_stereo_mask', 'anti_stereo_mask'])\n",
    "for index, row in df_data.iterrows():\n",
    "    \n",
    "    p = row['pro_stereo_sentence'].strip().split()\n",
    "    a = row['anti_stereo_sentence'].strip().split()\n",
    "    \n",
    "    template_prefix = []\n",
    "    for i in range(len(p)):\n",
    "        if p[i] == a[i]:\n",
    "            template_prefix = template_prefix + [p[i]]\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if len(template_prefix) == len(p):\n",
    "        print(row)\n",
    "        print()\n",
    "    \n",
    "    template_suffix = []\n",
    "    for i in range(len(p)):\n",
    "        if p[-i-1] == a[-i-1]:\n",
    "            template_suffix = [p[-i-1]] + template_suffix\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    pro_mask = ' '.join(p[len(template_prefix):-len(template_suffix)])\n",
    "    anti_mask = ' '.join(a[len(template_prefix):-len(template_suffix)])\n",
    "    \n",
    "    template_prefix = ' '.join(template_prefix)\n",
    "    template_suffix = ' '.join(template_suffix)\n",
    "    \n",
    "    df_templates = df_templates.append({'sentid': row['sentid'],\n",
    "                                        'template': template_prefix + ' [MASK] ' + template_suffix,\n",
    "                                        'pro_stereo_mask': pro_mask,\n",
    "                                        'anti_stereo_mask': anti_mask\n",
    "                                        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BERT stuff\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "mask_token = tokenizer.mask_token\n",
    "softmax = torch.nn.LogSoftmax(dim=0)\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "\n",
    "def probability(sentence, masked_position):\n",
    "    \"\"\"\n",
    "    Given sentence and masked_position of token that we want probability of\n",
    "    Return logprobability of that token\n",
    "    \"\"\"\n",
    "    \n",
    "    unmasked_word = sentence[masked_position] #grab word\n",
    "    sentence[masked_position] = mask_token #re-mask word in sentence\n",
    "    sentence = ' '.join(sentence)\n",
    "\n",
    "    token_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "    output = model(token_ids)\n",
    "    last_hidden_state = output[0].squeeze(0)\n",
    "    mask_hidden_state = last_hidden_state[masked_position]\n",
    "    probs = softmax(mask_hidden_state)\n",
    "\n",
    "    word_id = vocab.get(unmasked_word, None)\n",
    "    if word_id:\n",
    "        return probs[word_id].item()\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentence(to_unmask, unmasked):\n",
    "    \"\"\"\n",
    "    Given part in common between sentences (to_unmask) and part that is different (unmasked),\n",
    "    unmask the common part word by word. Return sum of logprobabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    [l, r] = to_unmask.split('[MASK]')\n",
    "    l = l.strip().split()\n",
    "    r = r.strip().split()\n",
    "    unmasked = unmasked.strip().split()\n",
    "    \n",
    "    score = 0\n",
    "    masked_sentence = [mask_token]*len(l) + unmasked + [mask_token]*len(r)\n",
    "    for i in range(len(l)):\n",
    "        masked_sentence[i] = l[i]\n",
    "        prob = probability(masked_sentence, i)\n",
    "        if prob:\n",
    "            score = score + prob\n",
    "    \n",
    "    for i in range(len(r)):\n",
    "        masked_sentence[len(l)+len(unmasked)+i] = r[i]\n",
    "        prob = probability(masked_sentence, len(l)+len(unmasked)+i)\n",
    "        if prob:\n",
    "            score = score + prob\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Score each sentence. Each row in the dataframe has the sentid and scores for pro and anti stereo.\n",
    "\"\"\"\n",
    "\n",
    "df_scores = pd.DataFrame(columns=['sentid', 'pro_stereo_score', 'anti_stereo_score'])\n",
    "for index, row in df_templates.iterrows():\n",
    "    template = row['template']\n",
    "    df_scores = df_scores.append({'sentid': row['sentid'],\n",
    "                                  'pro_stereo_score': score_sentence(template, row['pro_stereo_mask']),\n",
    "                                  'anti_stereo_score': score_sentence(template, row['anti_stereo_mask'])\n",
    "                                 },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_csv('winobias_left_to_right_logsoftmax.csv')\n",
    "df_scores.head(len(df_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
