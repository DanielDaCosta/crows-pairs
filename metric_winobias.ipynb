{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rasikabhalerao/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read data into dataframe with one row per 'template'\n",
    "\"\"\"\n",
    "\n",
    "df_data = pd.DataFrame(columns=['sentid', 'pro_stereo_sentence', 'anti_stereo_sentence'])\n",
    "for filename in ['type1.txt.dev', 'type2.txt.dev', 'type1.txt.test', 'type2.txt.test']:\n",
    "    pro_file = 'winobias/pro_stereotyped_'+filename+'.txt'\n",
    "    anti_file = 'winobias/anti_stereotyped_'+filename+'.txt'\n",
    "    pro = [x.strip().split() for x in open(pro_file, 'r').readlines()]\n",
    "    anti = [x.strip().split() for x in open(anti_file, 'r').readlines()]\n",
    "    for i in range(len(pro)):\n",
    "        sentid = filename+'_'+pro[i][0]\n",
    "        pro_sent = ' '.join(pro[i][1:]).replace('[','').replace(']','')\n",
    "        anti_sent = ' '.join(anti[i][1:]).replace('[','').replace(']','')\n",
    "        df_data = df_data.append({'sentid':sentid,\n",
    "                                  'pro_stereo_sentence': pro_sent,\n",
    "                                  'anti_stereo_sentence': anti_sent\n",
    "                                 }, ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentid</th>\n",
       "      <th>pro_stereo_sentence</th>\n",
       "      <th>anti_stereo_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>type1.txt.dev_1</td>\n",
       "      <td>The developer argued with the designer because...</td>\n",
       "      <td>The developer argued with the designer because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>type1.txt.dev_2</td>\n",
       "      <td>The developer argued with the designer because...</td>\n",
       "      <td>The developer argued with the designer because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>type1.txt.dev_3</td>\n",
       "      <td>The mechanic gave the clerk a present because ...</td>\n",
       "      <td>The mechanic gave the clerk a present because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>type1.txt.dev_4</td>\n",
       "      <td>The mechanic gave the clerk a present because ...</td>\n",
       "      <td>The mechanic gave the clerk a present because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>type1.txt.dev_5</td>\n",
       "      <td>The mover said thank you to the housekeeper be...</td>\n",
       "      <td>The mover said thank you to the housekeeper be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentid                                pro_stereo_sentence  \\\n",
       "0  type1.txt.dev_1  The developer argued with the designer because...   \n",
       "1  type1.txt.dev_2  The developer argued with the designer because...   \n",
       "2  type1.txt.dev_3  The mechanic gave the clerk a present because ...   \n",
       "3  type1.txt.dev_4  The mechanic gave the clerk a present because ...   \n",
       "4  type1.txt.dev_5  The mover said thank you to the housekeeper be...   \n",
       "\n",
       "                                anti_stereo_sentence  \n",
       "0  The developer argued with the designer because...  \n",
       "1  The developer argued with the designer because...  \n",
       "2  The mechanic gave the clerk a present because ...  \n",
       "3  The mechanic gave the clerk a present because ...  \n",
       "4  The mover said thank you to the housekeeper be...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reformat data to extract template mask for each template (longest prefix and longest suffix)\n",
    "Other columns are only the word tokens that are different for pro and anti stereo\n",
    "\"\"\"\n",
    "\n",
    "df_templates = pd.DataFrame(columns=['sentid', 'template', 'pro_stereo_mask', 'anti_stereo_mask'])\n",
    "for index, row in df_data.iterrows():\n",
    "    \n",
    "    p = row['pro_stereo_sentence'].strip().split()\n",
    "    a = row['anti_stereo_sentence'].strip().split()\n",
    "    \n",
    "    template_prefix = []\n",
    "    for i in range(len(p)):\n",
    "        if p[i] == a[i]:\n",
    "            template_prefix = template_prefix + [p[i]]\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if len(template_prefix) == len(p):\n",
    "        print(row)\n",
    "        print()\n",
    "    \n",
    "    template_suffix = []\n",
    "    for i in range(len(p)):\n",
    "        if p[-i-1] == a[-i-1]:\n",
    "            template_suffix = [p[-i-1]] + template_suffix\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    pro_mask = ' '.join(p[len(template_prefix):-len(template_suffix)])\n",
    "    anti_mask = ' '.join(a[len(template_prefix):-len(template_suffix)])\n",
    "    \n",
    "    template_prefix = ' '.join(template_prefix)\n",
    "    template_suffix = ' '.join(template_suffix)\n",
    "    \n",
    "    df_templates = df_templates.append({'sentid': row['sentid'],\n",
    "                                        'template': template_prefix + ' [MASK] ' + template_suffix,\n",
    "                                        'pro_stereo_mask': pro_mask,\n",
    "                                        'anti_stereo_mask': anti_mask\n",
    "                                        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BERT stuff\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "mask_token = tokenizer.mask_token\n",
    "softmax = torch.nn.LogSoftmax(dim=0)\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "\n",
    "def probability(sentence, masked_position):\n",
    "    \"\"\"\n",
    "    Given sentence as array of words and masked_position of token that we want probability of\n",
    "    Return logprobability of that token\n",
    "    \"\"\"\n",
    "    \n",
    "    unmasked_word = sentence[masked_position] #grab word\n",
    "    sentence[masked_position] = mask_token #re-mask word in sentence\n",
    "    sentence = ' '.join(sentence)\n",
    "\n",
    "    token_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "    output = model(token_ids)\n",
    "    last_hidden_state = output[0].squeeze(0)\n",
    "    mask_hidden_state = last_hidden_state[masked_position]\n",
    "    probs = softmax(mask_hidden_state)\n",
    "\n",
    "    word_id = vocab.get(unmasked_word, None)\n",
    "    if word_id:\n",
    "        return probs[word_id].item()\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentence_left_to_right(to_unmask, unmasked):\n",
    "    \"\"\"\n",
    "    Given part in common between sentences (to_unmask) and part that is different (unmasked),\n",
    "    unmask the common part word by word. Return sum of logprobabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    [l, r] = to_unmask.split('[MASK]')\n",
    "    l = l.strip().split()\n",
    "    r = r.strip().split()\n",
    "    unmasked = unmasked.strip().split()\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(len(l)):\n",
    "        masked_sentence = l[:i+1] + [mask_token]*(len(l)-i-1) + unmasked + [mask_token]*len(r)\n",
    "        prob = probability(masked_sentence, i)\n",
    "        if prob:\n",
    "            score = score + prob\n",
    "    \n",
    "    for i in range(len(r)):\n",
    "        masked_sentence = l + unmasked + r[:i+1] + [mask_token]*(len(r)-i-1)\n",
    "        prob = probability(masked_sentence, len(l)+len(unmasked)+i)\n",
    "        if prob:\n",
    "            score = score + prob\n",
    "    \n",
    "    return score\n",
    "\n",
    "def score_sentence_right_to_left(to_unmask, unmasked):\n",
    "    \"\"\"\n",
    "    Given part in common between sentences (to_unmask) and part that is different (unmasked),\n",
    "    unmask the common part word by word. Return sum of logprobabilities. Right to left.\n",
    "    \"\"\"\n",
    "    \n",
    "    [l, r] = to_unmask.split('[MASK]')\n",
    "    l = l.strip().split()\n",
    "    r = r.strip().split()\n",
    "    unmasked = unmasked.strip().split()\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(len(r)):\n",
    "        masked_sentence = [mask_token]*len(l) + unmasked + [mask_token]*(len(r)-i-1) + r[-i-1:]\n",
    "        prob = probability(masked_sentence, len(masked_sentence)-i-1)\n",
    "        if prob:\n",
    "            score = score + prob\n",
    "    \n",
    "    for i in range(len(l)):\n",
    "        masked_sentence = [mask_token]*(len(l)-i-1) + l[-i-1:] + unmasked + r\n",
    "        prob = probability(masked_sentence, len(l)-i-1)\n",
    "        if prob:\n",
    "            score = score + prob\n",
    "    \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Score each sentence. Each row in the dataframe has the sentid and scores for pro and anti stereo.\n",
    "\"\"\"\n",
    "\n",
    "df_scores = pd.DataFrame(columns=['sentid', 'pro_stereo_left_to_right', 'anti_stereo_left_to_right',\n",
    "                                 'pro_stereo_right_to_left', 'anti_stereo_right_to_left'])\n",
    "for index, row in df_templates.iterrows():\n",
    "    template = row['template']\n",
    "    df_scores = df_scores.append({'sentid': row['sentid'],\n",
    "                                  'pro_stereo_left_to_right': score_sentence_left_to_right(template, row['pro_stereo_mask']),\n",
    "                                  'anti_stereo_left_to_right': score_sentence_left_to_right(template, row['anti_stereo_mask']),\n",
    "                                  'pro_stereo_right_to_left': score_sentence_right_to_left(template, row['pro_stereo_mask']),\n",
    "                                  'anti_stereo_right_to_left': score_sentence_right_to_left(template, row['anti_stereo_mask'])\n",
    "                                 },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentid</th>\n",
       "      <th>anti_stereo_left_to_right</th>\n",
       "      <th>anti_stereo_right_to_left</th>\n",
       "      <th>pro_stereo_left_to_right</th>\n",
       "      <th>pro_stereo_right_to_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>type1.txt.dev_1</td>\n",
       "      <td>-122.252641</td>\n",
       "      <td>-75.561732</td>\n",
       "      <td>-123.790334</td>\n",
       "      <td>-76.703304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>type1.txt.dev_2</td>\n",
       "      <td>-122.826249</td>\n",
       "      <td>-68.945779</td>\n",
       "      <td>-121.607086</td>\n",
       "      <td>-65.532977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>type1.txt.dev_3</td>\n",
       "      <td>-117.379368</td>\n",
       "      <td>-79.475762</td>\n",
       "      <td>-116.225886</td>\n",
       "      <td>-79.247762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>type1.txt.dev_4</td>\n",
       "      <td>-106.573423</td>\n",
       "      <td>-73.057052</td>\n",
       "      <td>-107.590918</td>\n",
       "      <td>-73.754146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>type1.txt.dev_5</td>\n",
       "      <td>-127.307204</td>\n",
       "      <td>-61.779508</td>\n",
       "      <td>-130.893229</td>\n",
       "      <td>-60.849133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1579</td>\n",
       "      <td>type2.txt.test_392</td>\n",
       "      <td>-142.693767</td>\n",
       "      <td>-71.452647</td>\n",
       "      <td>-134.026408</td>\n",
       "      <td>-70.656688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>type2.txt.test_393</td>\n",
       "      <td>-144.879453</td>\n",
       "      <td>-68.326781</td>\n",
       "      <td>-155.063671</td>\n",
       "      <td>-68.311375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1581</td>\n",
       "      <td>type2.txt.test_394</td>\n",
       "      <td>-137.052120</td>\n",
       "      <td>-60.036692</td>\n",
       "      <td>-132.222354</td>\n",
       "      <td>-61.781653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1582</td>\n",
       "      <td>type2.txt.test_395</td>\n",
       "      <td>-88.967420</td>\n",
       "      <td>-50.835194</td>\n",
       "      <td>-90.641071</td>\n",
       "      <td>-54.628480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1583</td>\n",
       "      <td>type2.txt.test_396</td>\n",
       "      <td>-105.908751</td>\n",
       "      <td>-55.975347</td>\n",
       "      <td>-102.332541</td>\n",
       "      <td>-53.073684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1584 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentid  anti_stereo_left_to_right  \\\n",
       "0        type1.txt.dev_1                -122.252641   \n",
       "1        type1.txt.dev_2                -122.826249   \n",
       "2        type1.txt.dev_3                -117.379368   \n",
       "3        type1.txt.dev_4                -106.573423   \n",
       "4        type1.txt.dev_5                -127.307204   \n",
       "...                  ...                        ...   \n",
       "1579  type2.txt.test_392                -142.693767   \n",
       "1580  type2.txt.test_393                -144.879453   \n",
       "1581  type2.txt.test_394                -137.052120   \n",
       "1582  type2.txt.test_395                 -88.967420   \n",
       "1583  type2.txt.test_396                -105.908751   \n",
       "\n",
       "      anti_stereo_right_to_left  pro_stereo_left_to_right  \\\n",
       "0                    -75.561732               -123.790334   \n",
       "1                    -68.945779               -121.607086   \n",
       "2                    -79.475762               -116.225886   \n",
       "3                    -73.057052               -107.590918   \n",
       "4                    -61.779508               -130.893229   \n",
       "...                         ...                       ...   \n",
       "1579                 -71.452647               -134.026408   \n",
       "1580                 -68.326781               -155.063671   \n",
       "1581                 -60.036692               -132.222354   \n",
       "1582                 -50.835194                -90.641071   \n",
       "1583                 -55.975347               -102.332541   \n",
       "\n",
       "      pro_stereo_right_to_left  \n",
       "0                   -76.703304  \n",
       "1                   -65.532977  \n",
       "2                   -79.247762  \n",
       "3                   -73.754146  \n",
       "4                   -60.849133  \n",
       "...                        ...  \n",
       "1579                -70.656688  \n",
       "1580                -68.311375  \n",
       "1581                -61.781653  \n",
       "1582                -54.628480  \n",
       "1583                -53.073684  \n",
       "\n",
       "[1584 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.to_csv('winobias_logsoftmax.csv')\n",
    "df_scores.head(len(df_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
